one file for preprocessing

one file per model				load data
	tree					          predict-classify (forward pass)
	mlp					            train or error correct (backward pass)
	bayesian                save assembled model
												  test
													evaluation metrics

one file for prediction   load trained model
													forward pass
													save predictions

one file for feature engineering        load data
																				create CNN
																				apply CNN
																				visualize features
																				save features

one file for correlation test			load data
																	apply correlation tests
																	select columns based on significance
																	save only needed


MAJOR PROBLEM: only 908 labeled records
			K-fold with replacement

TODO:
normalize areas? keep as ordinal?
num of transfer as pie chart

sample algorithms on given data
ensemble

silhouettes samples for cluster membership

save only as cPickle for faster read write



Papers to get:
Reconstructing individual mobility from smart card transactions: a collaborative space alignment approach


Improvements to report:
transfer time focus on tail
thesis organization more technical, and methods per parts
Mention hierarchy in traffic areas will cause correlation
Attributes summary: numerical vs categorical
Section: deal with categorical -> tokenize, encode, bins
comment on ordinal structure vs one hot
random forests deal well with categorical (large node size), adaboost with missing info
