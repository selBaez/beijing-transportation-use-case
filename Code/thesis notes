one file for preprocessing			save processed data
						read csv
						mean shift, std shrink


one file per model				save model type
	tree					predict-classify (forward pass)
	mlp					train or error correct (backward pass)
	bayesian

one file for training (ensemble)		save assembled model


one file for testing 				metrics for accuracy
						False positives, etc
						plots and stuff (matplotlib)



MAJOR PROBLEM
	validation info: on 908 mentioned on paper
			K-fold with replacement

TODO:
vocabulary of stops
recalculate transfer number
reconsider the min_records approach
standardize transfer time
plot transfer time, num transfers
parse route using regular expressions, translate dictionary and stops vocabulary



distance calculation for bikes? dunno
How much data to handle? 100,000 per day * month = 3,000,000 ~ 33% kept
